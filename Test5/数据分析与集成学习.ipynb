{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:07:32.309306500Z",
     "start_time": "2025-05-22T08:07:32.294315Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "try:\n",
    "    data = pd.read_csv('sales_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"数据集文件未找到，请检查文件名和路径。\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:07:33.165027600Z",
     "start_time": "2025-05-22T08:07:32.305920600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值情况：\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            166986\n",
      "Product_Category_3            373299\n",
      "Purchase                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 检查缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 缺失值填充（这里简单用0填充，实际可根据情况调整）\n",
    "data.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:07:42.253598Z",
     "start_time": "2025-05-22T08:07:41.875345600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# 类别特征编码\n",
    "categorical_columns = ['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(data[categorical_columns])\n",
    "# 由于OneHotEncoder在新版本返回稀疏矩阵，需要转换为密集数组\n",
    "encoded_df = pd.DataFrame(encoded_features.toarray(), columns=encoder.get_feature_names_out(categorical_columns))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:10:35.803891500Z",
     "start_time": "2025-05-22T08:10:34.754679300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# 数值特征标准化\n",
    "numerical_columns = ['Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:10:43.869781800Z",
     "start_time": "2025-05-22T08:10:43.783299300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 合并编码后的类别特征和标准化后的数值特征\n",
    "data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# 划分训练集和测试集（以Purchase为预测目标，假设这是一个回归问题）\n",
    "X = data.drop('Purchase', axis=1)\n",
    "y = data['Purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:10:47.760691800Z",
     "start_time": "2025-05-22T08:10:46.763924500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# 注释：\n",
    "# 导入必要的库，pandas用于数据处理，StandardScaler用于数值特征标准化，OneHotEncoder用于类别特征编码，train_test_split用于划分数据集。\n",
    "# 尝试读取数据集，若文件不存在则提示错误。\n",
    "# 检查数据集中的缺失值，并使用 0 填充缺失值（实际应用中可能需要更合理的填充策略）。\n",
    "# 对类别特征进行独热编码，将编码后的特征转换为DataFrame。\n",
    "# 对数值特征进行标准化处理。\n",
    "# 将编码后的类别特征和标准化后的数值特征合并。\n",
    "# 划分训练集和测试集，这里假设Purchase是预测目标，将数据集按 70% 训练集、30% 测试集的比例划分，并设置随机种子以确保结果可重复性。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:11:15.392166600Z",
     "start_time": "2025-05-22T08:11:15.351200400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 分类 / 回归与聚类分析"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:11:31.863328800Z",
     "start_time": "2025-05-22T08:11:31.828666400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值情况：\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            166986\n",
      "Product_Category_3            373299\n",
      "Purchase                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "try:\n",
    "    data = pd.read_csv('sales_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"数据集文件未找到，请检查文件名和路径。\")\n",
    "\n",
    "# 检查缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 缺失值填充（这里简单用0填充，实际可根据情况调整）\n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "# 对Product_ID进行编码\n",
    "le = LabelEncoder()\n",
    "data['Product_ID'] = le.fit_transform(data['Product_ID'])\n",
    "\n",
    "# 类别特征编码\n",
    "categorical_columns = ['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(data[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded_features.toarray(), columns = encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# 数值特征标准化\n",
    "numerical_columns = ['Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# 合并编码后的类别特征和标准化后的数值特征\n",
    "data = pd.concat([data.drop(categorical_columns, axis = 1), encoded_df], axis = 1)\n",
    "\n",
    "# 划分训练集和测试集（以Purchase为预测目标，假设这是一个回归问题）\n",
    "X = data.drop('Purchase', axis = 1)\n",
    "y = data['Purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:16:09.065514800Z",
     "start_time": "2025-05-22T08:16:05.939583800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, silhouette_score\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:16:11.358736400Z",
     "start_time": "2025-05-22T08:16:11.339908800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树回归RMSE: 0.70\n"
     ]
    }
   ],
   "source": [
    "# 回归任务：决策树回归\n",
    "regressor = DecisionTreeRegressor(max_depth=5)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"决策树回归RMSE: {rmse:.2f}\")\n",
    "\n",
    "\n",
    "# # 聚类任务：K均值聚类\n",
    "# kmeans = KMeans(n_clusters=3)\n",
    "# clusters = kmeans.fit_predict(X)\n",
    "# silhouette_avg = silhouette_score(X, clusters)\n",
    "# print(f\"K均值聚类轮廓系数: {silhouette_avg:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:18:51.217539500Z",
     "start_time": "2025-05-22T08:18:49.184531800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# 注释：\n",
    "# 导入DecisionTreeRegressor用于回归任务，KMeans用于聚类任务，mean_squared_error用于计算回归的均方误差，silhouette_score用于评估聚类效果，np用于数值计算。\n",
    "# 初始化决策树回归器，设置最大深度为 5，然后在训练集上进行训练，并在测试集上进行预测，计算并打印均方根误差（RMSE）。\n",
    "# 初始化 K 均值聚类器，设置聚类数为 3，对整个数据集进行聚类，并计算和打印轮廓系数，以评估聚类效果。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:18:54.455639600Z",
     "start_time": "2025-05-22T08:18:54.437153500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost回归RMSE: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Adaboost回归（基于决策树）\n",
    "ada = AdaBoostRegressor(estimator = DecisionTreeRegressor(max_depth = 2), n_estimators = 50)\n",
    "ada.fit(X_train, y_train)\n",
    "ada_rmse = np.sqrt(mean_squared_error(y_test, ada.predict(X_test)))\n",
    "print(f\"Adaboost回归RMSE: {ada_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:21:44.549582800Z",
     "start_time": "2025-05-22T08:21:30.003506600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林回归RMSE: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 随机森林回归\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "print(f\"随机森林回归RMSE: {rf_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:26:06.258587700Z",
     "start_time": "2025-05-22T08:22:09.490112300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "调优后Adaboost回归RMSE: 0.71\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 定义基础估计器\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "\n",
    "# 超参数调优 - Adaboost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "grid_search_ada = GridSearchCV(AdaBoostRegressor(estimator = base_estimator), param_grid_ada, cv = 5)\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "best_ada = grid_search_ada.best_estimator_\n",
    "best_ada_rmse = np.sqrt(mean_squared_error(y_test, best_ada.predict(X_test)))\n",
    "print(f\"调优后Adaboost回归RMSE: {best_ada_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-22T08:41:16.885951800Z",
     "start_time": "2025-05-22T08:28:09.059821400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 超参数调优 - 随机森林\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "   'max_depth': [5, 10, 15]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(RandomForestRegressor(), param_grid_rf, cv=5)\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "best_rf_rmse = np.sqrt(mean_squared_error(y_test, best_rf.predict(X_test)))\n",
    "print(f\"调优后随机森林回归RMSE: {best_rf_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-05-22T08:50:30.459875800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 模型性能对比表\n",
    "performance_df = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Adaboost', 'Random Forest', 'Tuned Adaboost', 'Tuned Random Forest'],\n",
    "    'RMSE': [rmse, ada_rmse, rf_rmse, best_ada_rmse, best_rf_rmse]\n",
    "})\n",
    "print(\"\\n模型性能对比表：\")\n",
    "print(performance_df)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 注释：\n",
    "# 导入AdaBoostRegressor和RandomForestRegressor用于集成学习回归，GridSearchCV用于超参数调优。\n",
    "# 初始化并训练 Adaboost 回归器，基于深度为 2 的决策树，设置 50 个弱学习器，计算并打印其 RMSE。\n",
    "# 初始化并训练随机森林回归器，设置 100 个决策树，最大深度为 10，计算并打印其 RMSE。\n",
    "# 对 Adaboost 进行超参数调优，通过GridSearchCV搜索不同的n_estimators和base_estimator__max_depth组合，进行 5 折交叉验证，找到最佳模型并计算其 RMSE。\n",
    "# 对随机森林进行超参数调优，通过GridSearchCV搜索不同的n_estimators和max_depth组合，进行 5 折交叉验证，找到最佳模型并计算其 RMSE。\n",
    "# 创建一个DataFrame来展示不同模型的 RMSE，方便对比模型性能。"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 模型解释 - 特征重要性分析"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 随机森林特征重要性分析\n",
    "feature_importances = pd.Series(best_rf.feature_importances_, index=X.columns)\n",
    "feature_importances.nlargest(10).plot(kind='barh')\n",
    "plt.title('Top 10 Feature Importances - Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.show()\n",
    "\n",
    "# 保存特征重要性图为PNG\n",
    "plt.savefig('feature_importance.png')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注释：\n",
    "导入matplotlib.pyplot用于数据可视化。\n",
    "获取调优后随机森林模型的特征重要性，并转换为Series，索引为特征名称。\n",
    "绘制前 10 个最重要特征的水平柱状图，展示特征重要性。\n",
    "保存特征重要性图为feature_importance.png文件。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "performance_df.to_csv('model_performance.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "注释：\n",
    "将模型性能对比表保存为model_performance.csv文件，不保存索引列。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "数据集说明：在报告中详细描述sales_data.csv数据集的来源、各字段的含义、数据类型以及数据量等信息。说明数据预处理过程中对缺失值、类别特征和数值特征的处理方法及其原因。\n",
    "模型性能对比表：展示上述代码生成的performance_df表格，分析不同模型（决策树、Adaboost、随机森林以及调优后的 Adaboost 和随机森林）的 RMSE 差异，说明集成学习方法相较于单一决策树模型在性能上的提升。\n",
    "集成学习效果分析：解释 Adaboost 和随机森林这两种集成学习方法的原理，分析它们在本实验中的表现。例如，说明 Adaboost 如何通过迭代训练弱学习器并调整样本权重来提升性能，随机森林如何通过构建多个决策树并综合结果来减少方差。分析两种集成方法在本数据集上的优缺点。\n",
    "参数调优过程：阐述在GridSearchCV中选择param_grid_ada和param_grid_rf参数范围的依据。说明调优过程如何帮助找到最佳超参数，以及这些超参数对模型性能的影响。例如，增加n_estimators可能提高模型的拟合能力，但也可能增加计算时间和过拟合风险；调整max_depth可以控制树的复杂度，避免过拟合或欠拟合。\n",
    "集成方法的选择依据：在报告中解释选择 Adaboost 和随机森林的原因。例如，随机森林适用于高维数据，具有较好的抗噪声能力和泛化性能，适合处理本数据集中多个特征的情况；Adaboost 对异常值敏感，所以选择简单的浅层决策树作为基模型，通过不断调整样本权重，能够提升弱学习器的性能。\n",
    "不同集成方法的适用场景：分析随机森林和 Adaboost 在不同场景下的优势。例如，随机森林在特征交互复杂时表现更优，因为它通过随机选择特征和样本构建多个决策树，能够捕捉到更多的特征组合和复杂关系；Adaboost 适用于对精度要求较高且数据噪声较小的场景，因为它通过迭代训练可以逐步聚焦于难以分类的样本。"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
