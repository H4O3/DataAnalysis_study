{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:27.759552400Z",
     "start_time": "2025-06-05T07:28:27.706984400Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "<joblib.parallel.parallel_backend at 0x1abef5f1d90>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 内存优化配置\n",
    "import joblib\n",
    "from sklearn import config_context\n",
    "\n",
    "# 设置全局并行作业数\n",
    "config_context(print_changed_only=True)\n",
    "joblib.parallel_backend('loky', n_jobs=4)  # 根据CPU核心数调整"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:27.838147200Z",
     "start_time": "2025-06-05T07:28:27.714705100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "try:\n",
    "    data = pd.read_csv('sales_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"数据集文件未找到，请检查文件名和路径。\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:28.385442600Z",
     "start_time": "2025-06-05T07:28:27.726685300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值情况：\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            166986\n",
      "Product_Category_3            373299\n",
      "Purchase                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 检查缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 缺失值填充（这里简单用0填充，实际可根据情况调整）\n",
    "data.fillna(0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:28.634864600Z",
     "start_time": "2025-06-05T07:28:28.387479500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# 类别特征编码（将离散型分类变量转换为数值型哑变量）\n",
    "# 定义需要独热编码的类别型特征列\n",
    "categorical_columns = [\n",
    "    'Gender',                   # 性别（二分类：男/女）\n",
    "    'Age',                      # 年龄段（多分类，如18-25、26-35等）\n",
    "    'Occupation',               # 职业类别（多分类编码）\n",
    "    'City_Category',            # 城市分类（如A/B/C类城市）\n",
    "    'Stay_In_Current_City_Years',# 在当前城市居住年限（有序分类）\n",
    "    'Marital_Status'            # 婚姻状态（二分类：已婚/未婚）\n",
    "]\n",
    "\n",
    "# 初始化独热编码器对象\n",
    "# sparse=True时返回稀疏矩阵，节省内存空间（sklearn>=1.2版本默认sparse_output=True）\n",
    "encoder = OneHotEncoder(sparse_output=True)\n",
    "\n",
    "# 同时进行编码器拟合（学习类别）和特征转换\n",
    "# 输入必须是二维结构（DataFrame或二维数组），输出为稀疏矩阵格式\n",
    "encoded_features = encoder.fit_transform(data[categorical_columns])\n",
    "\n",
    "# 将稀疏矩阵转换为密集数组（numpy.ndarray）\n",
    "# 原因：后续合并到DataFrame需要密集数据格式，且当前数据规模可承受内存消耗\n",
    "# 注意：当类别数量极大时，此操作可能引发内存问题，此时应保持稀疏格式\n",
    "encoded_array = encoded_features.toarray()\n",
    "\n",
    "# 创建包含编码特征的DataFrame\n",
    "# 使用编码器生成的列名（格式如：Gender_Female, Gender_Male）\n",
    "# get_feature_names_out() 方法自动生成格式为\"特征名_类别值\"的列名\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_array,\n",
    "    columns=encoder.get_feature_names_out(categorical_columns)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:29.328874300Z",
     "start_time": "2025-06-05T07:28:28.640577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# 数值特征标准化\n",
    "numerical_columns = ['Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:29.400601300Z",
     "start_time": "2025-06-05T07:28:29.329874Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# 合并编码后的类别特征和标准化后的数值特征\n",
    "data = pd.concat([data.drop(categorical_columns, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# 划分训练集和测试集（以Purchase为预测目标，假设这是一个回归问题）\n",
    "X = data.drop('Purchase', axis=1)\n",
    "y = data['Purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:30.048167800Z",
     "start_time": "2025-06-05T07:28:29.401601400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# 注释：\n",
    "# 导入必要的库，pandas用于数据处理，StandardScaler用于数值特征标准化，OneHotEncoder用于类别特征编码，train_test_split用于划分数据集。\n",
    "# 尝试读取数据集，若文件不存在则提示错误。\n",
    "# 检查数据集中的缺失值，并使用 0 填充缺失值（实际应用中可能需要更合理的填充策略）。\n",
    "# 对类别特征进行独热编码，将编码后的特征转换为DataFrame。\n",
    "# 对数值特征进行标准化处理。\n",
    "# 将编码后的类别特征和标准化后的数值特征合并。\n",
    "# 划分训练集和测试集，这里假设Purchase是预测目标，将数据集按 70% 训练集、30% 测试集的比例划分，并设置随机种子以确保结果可重复性。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:30.058145800Z",
     "start_time": "2025-06-05T07:28:30.050168500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# 分类 / 回归与聚类分析"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:30.068952800Z",
     "start_time": "2025-06-05T07:28:30.060597500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "缺失值情况：\n",
      "User_ID                            0\n",
      "Product_ID                         0\n",
      "Gender                             0\n",
      "Age                                0\n",
      "Occupation                         0\n",
      "City_Category                      0\n",
      "Stay_In_Current_City_Years         0\n",
      "Marital_Status                     0\n",
      "Product_Category_1                 0\n",
      "Product_Category_2            166986\n",
      "Product_Category_3            373299\n",
      "Purchase                           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 加载数据\n",
    "try:\n",
    "    data = pd.read_csv('sales_data.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"数据集文件未找到，请检查文件名和路径。\")\n",
    "\n",
    "# 检查缺失值\n",
    "print(\"缺失值情况：\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# 缺失值填充（这里简单用0填充，实际可根据情况调整）\n",
    "data.fillna(0, inplace = True)\n",
    "\n",
    "# 对Product_ID进行编码\n",
    "le = LabelEncoder()\n",
    "data['Product_ID'] = le.fit_transform(data['Product_ID'])\n",
    "\n",
    "# 类别特征编码\n",
    "categorical_columns = ['Gender', 'Age', 'Occupation', 'City_Category', 'Stay_In_Current_City_Years', 'Marital_Status']\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(data[categorical_columns])\n",
    "encoded_df = pd.DataFrame(encoded_features.toarray(), columns = encoder.get_feature_names_out(categorical_columns))\n",
    "\n",
    "# 数值特征标准化\n",
    "numerical_columns = ['Product_Category_1', 'Product_Category_2', 'Product_Category_3', 'Purchase']\n",
    "scaler = StandardScaler()\n",
    "data[numerical_columns] = scaler.fit_transform(data[numerical_columns])\n",
    "\n",
    "# 合并编码后的类别特征和标准化后的数值特征\n",
    "data = pd.concat([data.drop(categorical_columns, axis = 1), encoded_df], axis = 1)\n",
    "\n",
    "# 划分训练集和测试集（以Purchase为预测目标，假设这是一个回归问题）\n",
    "X = data.drop('Purchase', axis = 1)\n",
    "y = data['Purchase']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:32.526086200Z",
     "start_time": "2025-06-05T07:28:30.076016900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import mean_squared_error, silhouette_score\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:32.533061500Z",
     "start_time": "2025-06-05T07:28:32.527086300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "决策树回归RMSE: 0.70\n"
     ]
    }
   ],
   "source": [
    "# 回归任务：决策树回归\n",
    "regressor = DecisionTreeRegressor(max_depth=5)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"决策树回归RMSE: {rmse:.2f}\")\n",
    "\n",
    "\n",
    "# # 聚类任务：K均值聚类\n",
    "# kmeans = KMeans(n_clusters=3)\n",
    "# clusters = kmeans.fit_predict(X)\n",
    "# silhouette_avg = silhouette_score(X, clusters)\n",
    "# print(f\"K均值聚类轮廓系数: {silhouette_avg:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:34.230044800Z",
     "start_time": "2025-06-05T07:28:32.535158300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# 注释：\n",
    "# 导入DecisionTreeRegressor用于回归任务，KMeans用于聚类任务，mean_squared_error用于计算回归的均方误差，silhouette_score用于评估聚类效果，np用于数值计算。\n",
    "# 初始化决策树回归器，设置最大深度为 5，然后在训练集上进行训练，并在测试集上进行预测，计算并打印均方根误差（RMSE）。\n",
    "# 初始化 K 均值聚类器，设置聚类数为 3，对整个数据集进行聚类，并计算和打印轮廓系数，以评估聚类效果。"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:34.231106700Z",
     "start_time": "2025-06-05T07:28:34.213614500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost回归RMSE: 0.79\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Adaboost回归（基于决策树）\n",
    "ada = AdaBoostRegressor(estimator = DecisionTreeRegressor(max_depth = 2), n_estimators = 50)\n",
    "ada.fit(X_train, y_train)\n",
    "ada_rmse = np.sqrt(mean_squared_error(y_test, ada.predict(X_test)))\n",
    "print(f\"Adaboost回归RMSE: {ada_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:28:51.372595100Z",
     "start_time": "2025-06-05T07:28:34.225043500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林回归RMSE: 0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# 随机森林回归\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))\n",
    "print(f\"随机森林回归RMSE: {rf_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T07:30:05.082792800Z",
     "start_time": "2025-06-05T07:28:51.372595100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 定义基础估计器\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "\n",
    "# 超参数调优 - Adaboost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'estimator__max_depth': [1, 2, 3]\n",
    "}\n",
    "grid_search_ada = GridSearchCV(AdaBoostRegressor(estimator = base_estimator), param_grid_ada, cv = 5)\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "best_ada = grid_search_ada.best_estimator_\n",
    "best_ada_rmse = np.sqrt(mean_squared_error(y_test, best_ada.predict(X_test)))\n",
    "print(f\"调优后Adaboost回归RMSE: {best_ada_rmse:.2f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-06-05T07:30:05.082792800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# === 数据预处理 ===\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 处理缺失值（Product_Category_2/3存在空值）\n",
    "data = pd.read_csv('purchase_data.csv')\n",
    "data.fillna({'Product_Category_2':0, 'Product_Category_3':0}, inplace=True)\n",
    "\n",
    "# 特征工程\n",
    "# 年龄分段转换为数值（0-17 -> 0, 18-25 -> 1,...）\n",
    "age_mapping = {'0-17':0, '18-25':1, '26-35':2, '36-45':3, '46-50':4, '51-55':5, '55+':6}\n",
    "data['Age'] = data['Age'].map(age_mapping)\n",
    "\n",
    "# 编码分类特征\n",
    "le = LabelEncoder()\n",
    "data['Gender'] = le.fit_transform(data['Gender'])\n",
    "data['City_Category'] = le.fit_transform(data['City_Category'])\n",
    "\n",
    "# === 类别不平衡处理 ===\n",
    "from sklearn.utils import class_weight\n",
    "classes = data['Purchase'].unique()\n",
    "weights = class_weight.compute_class_weight('balanced', classes=classes, y=data['Purchase'])\n",
    "class_weights = dict(zip(classes, weights))\n",
    "\n",
    "# === 参数调优 ===\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'class_weight': [None, 'balanced', class_weights]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# === 特征重要性分析 ===\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rf_best = grid_search.best_estimator_\n",
    "features = X_train.columns\n",
    "importances = rf_best.feature_importances_\n",
    "\n",
    "# === 特征重要性分析 ===（修正版本）\n",
    "plt.figure(figsize=(10,6))\n",
    "# 确保使用正确的特征名称（X.columns）\n",
    "sorted_idx = importances.argsort()\n",
    "plt.barh(X.columns[sorted_idx], importances[sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.savefig('feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# === 内存优化（大规模数据示例）===\n",
    "# 分块读取数据示例\n",
    "chunk_size = 10**5\n",
    "data_chunks = pd.read_csv('big_data.csv', chunksize=chunk_size)\n",
    "\n",
    "# === 结果保存 ===（修正版本）\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['AdaBoost', 'RandomForest', 'Tuned_AdaBoost'],\n",
    "    'RMSE': [ada_rmse, rf_rmse, best_ada_rmse],  # 使用已计算的RMSE变量\n",
    "    'Best_Params': [\n",
    "        '',\n",
    "        str(grid_search_ada.best_params_),  # 使用实际存在的调参对象\n",
    "        str(grid_search.best_params_)\n",
    "    ]\n",
    "})\n",
    "results.to_csv('model_evaluation.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# === 结果保存 ===（修正版本）\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['AdaBoost', 'RandomForest', 'Tuned_AdaBoost'],\n",
    "    'RMSE': [ada_rmse, rf_rmse, best_ada_rmse],  # 使用已计算的RMSE变量\n",
    "    'Best_Params': [\n",
    "        '',\n",
    "        str(grid_search_ada.best_params_),  # 使用实际存在的调参对象\n",
    "        str(grid_search.best_params_)\n",
    "    ]\n",
    "})\n",
    "results.to_csv('model_evaluation.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
